{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('stand at attention', {'image': {'V', 'CP', 'L', 'B'}, 'group': 1, 'embedding': [4.0, 6.08, 5.0, 3.08, 2.08]})\n",
      "('stand out in several sports', {'image': {'R', 'V', 'L', 'B', 'CP'}, 'group': 1, 'embedding': [2.13, 3.54, 2.83, 5.04, 3.42]})\n",
      "('to stand firm', {'image': {'V', 'R', 'CP', 'L', 'B'}, 'group': 2, 'embedding': [6.21, 4.13, 5.04, 3.75, 2.83]})\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "##############\n",
    "# These sentences show the different forms of the word 'stand' to show the value of contextualized embeddings\n",
    "import csv\n",
    "\n",
    "texts = list()\n",
    "schemas = dict()\n",
    "\n",
    "with open('data/stand_rich.csv') as file:\n",
    "    for line in files:\n",
    "        tokens = line.split('\\t')\n",
    "        texts.append(line)\n",
    "    read_csv = csv.reader(file, delimiter='\\t')\n",
    "\n",
    "    header = next(read_csv)\n",
    "    heads = ['image', 'group', 'embedding']\n",
    "    # schemas['stand'] = { head: None for head in heads }\n",
    "\n",
    "    for n, values in enumerate(read_csv):\n",
    "\n",
    "        expression = values[0]\n",
    "        image = set(values[1].split(\"-\"))\n",
    "        group = int(values[2])\n",
    "        embedding = [float(value) for value in values[3:]]\n",
    "\n",
    "        entry = { key: value for key, value in zip(heads, [image, group, embedding])}\n",
    "        schemas[expression] = entry\n",
    "        texts.append(expression)\n",
    "\n",
    "        if n == 2: [print(item) for item in schemas.items()]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "# get openai embeddings\n",
    "openai_similarity_embedding_models = [\n",
    "    'text-similarity-ada-001',\n",
    "    'text-similarity-babbage-001',\n",
    "    'text-similarity-curie-001',\n",
    "    'text-similarity-davinci-001',\n",
    "]\n",
    "\n",
    "create_openai_embeddings = False\n",
    "# create_openai_embeddings = True\n",
    "if create_openai_embeddings:\n",
    "    n = 0\n",
    "    openai_similarity_embeddings = defaultdict(list)\n",
    "    for model in openai_similarity_embedding_models:\n",
    "        for text in texts:\n",
    "            # RateLimitError: Rate limit reached for default in organization\n",
    "            n=+1\n",
    "            if n % 10:\n",
    "                time.sleep(3)\n",
    "            response = openai.Embedding.create(\n",
    "                 input=text,\n",
    "                 model=model )\n",
    "            embeddings = response['data'][0]['embedding']\n",
    "            openai_similarity_embeddings[model].append(embeddings)\n",
    "\n",
    "    with open('data/openai_similarity_embeddings.json', 'w') as json_file:\n",
    "        json.dump(openai_similarity_embeddings, json_file)\n",
    "else:\n",
    "    with open('data/openai_similarity_embeddings.json') as json_file:\n",
    "        openai_similarity_embeddings = json.load(json_file)\n",
    "\n",
    "# experimental conditions\n",
    "conditions = [f'gpt3_{model.split(\"-\")[2]}'\n",
    "              for model in openai_similarity_embedding_models]\n",
    "\n",
    "embeddings = { condition:\n",
    "                   openai_similarity_embeddings[openai_similarity_embedding_model]\n",
    "               for condition, openai_similarity_embedding_model\n",
    "                in zip(conditions, openai_similarity_embedding_models)\n",
    "               }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Loading the pre-trained BERT model\n",
    "###################################\n",
    "# Embeddings will be derived from\n",
    "\n",
    "# the outputs of this model\n",
    "model = BertModel.from_pretrained('bert-base-uncased',\n",
    "                                  output_hidden_states = True,\n",
    "                                  )\n",
    "\n",
    "# Setting up the tokenizer\n",
    "###################################\n",
    "# This is the same tokenizer that\n",
    "# was used in the model to generate\n",
    "# embeddings to ensure consistency\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def bert_text_preparation(text, tokenizer):\n",
    "    \"\"\"Preparing the input for BERT\n",
    "    \n",
    "    Takes a string argument and performs pre-processing like adding special tokens, tokenization,\n",
    "    tokens to ids, and tokens to segment ids. All tokens are mapped to segment id = 1.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Text to be converted tokenizer (obj): Tokenizer object\n",
    "            to convert text into BERT-readable tokens and ids\n",
    "        \n",
    "    Returns:\n",
    "        list: List of BERT-readable tokens\n",
    "        obj: Torch tensor with token ids\n",
    "        obj: Torch tensor segment ids\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "    tokenized_text = tokenizer.tokenize(marked_text)\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    segments_ids = [1]*len(indexed_tokens)\n",
    "\n",
    "\n",
    "    # Convert inputs to PyTorch tensors\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "    return tokenized_text, tokens_tensor, segments_tensors\n",
    "    \n",
    "def get_bert_embeddings(tokens_tensor, segments_tensors, model):\n",
    "    \"\"\"Get embeddings from an embedding model\n",
    "\n",
    "    Args:\n",
    "        tokens_tensor (obj): Torch tensor size [n_tokens]\n",
    "            with token ids for each token in text\n",
    "        segments_tensors (obj): Torch tensor size [n_tokens]\n",
    "            with segment ids for each token in text\n",
    "        model (obj): Embedding model to generate embeddings\n",
    "            from token and segment ids\n",
    "\n",
    "    Returns:\n",
    "        list: List of list of floats of size\n",
    "            [n_tokens, n_embedding_dimensions]\n",
    "            containing embeddings for each token\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Gradient calculation id disabled\n",
    "    # Model is in inference mode\n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens_tensor, segments_tensors)\n",
    "        # Removing the first hidden state\n",
    "        # The first state is the input state\n",
    "        hidden_states = outputs[2][1:]\n",
    "\n",
    "    # Getting embeddings from the final BERT layer\n",
    "    token_embeddings = hidden_states[-1]\n",
    "    # Collapsing the tensor into 1-dimension\n",
    "    token_embeddings = torch.squeeze(token_embeddings, dim=0)\n",
    "    # Converting torchtensors to lists\n",
    "    list_token_embeddings = [token_embed.tolist() for token_embed in token_embeddings]\n",
    "\n",
    "    return list_token_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Getting embeddings for the target\n",
    "# word in all given contexts\n",
    "target_word_embeddings = []\n",
    "\n",
    "for text in texts:\n",
    "    tokenized_text, tokens_tensor, segments_tensors = bert_text_preparation(text, tokenizer)\n",
    "    list_token_embeddings = get_bert_embeddings(tokens_tensor, segments_tensors, model)\n",
    "\n",
    "    # include variations of stand\n",
    "    for variation in ['stand', 'stood', 'stands', 'standing']:\n",
    "        tokenized_text = list(map(lambda x: x.replace(variation, 'stand'), tokenized_text))\n",
    "\n",
    "    # Find the position 'stand' in list of tokens\n",
    "    word_index = tokenized_text.index('stand')\n",
    "    # Get the embedding for bank\n",
    "    word_embedding = list_token_embeddings[word_index]\n",
    "\n",
    "    target_word_embeddings.append(word_embedding)\n",
    "\n",
    "embeddings['bert'] = target_word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Getting embeddings for the target as above\n",
    "# word in all given contexts\n",
    "\n",
    "human_sentence_embeddings = []\n",
    "\n",
    "for expression in texts:\n",
    "    sentence_embedding = schemas[expression]['embedding']\n",
    "    human_sentence_embeddings.append( sentence_embedding )\n",
    "\n",
    "embeddings['human_label'] = human_sentence_embeddings"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "# Calculating the distance between the\n",
    "# embeddings of 'bank' in all the\n",
    "# given contexts of the word\n",
    "\n",
    "def get_distance_df(target_embeddings):\n",
    "    list_of_distances = []\n",
    "    for text1, embed1 in zip(texts, target_embeddings):\n",
    "        for text2, embed2 in zip(texts, target_embeddings):\n",
    "            cos_dist = cosine(embed1, embed2)\n",
    "            list_of_distances.append([text1, text2, cos_dist])\n",
    "\n",
    "    distances_df = pd.DataFrame(list_of_distances, columns=['text1', 'text2', 'distance'])\n",
    "    return distances_df\n",
    "\n",
    "def get_distance_array(target_embeddings):\n",
    "    distances_df = get_distance_df(target_embeddings)\n",
    "    distance_matrix = pd.pivot_table(distances_df,\n",
    "                        values='distance', index='text1', columns='text2')\n",
    "    distance_array = np.array(distance_matrix)\n",
    "    return distance_array, distance_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gpt3_ada', 'gpt3_babbage', 'gpt3_curie', 'gpt3_davinci', 'bert', 'human_label']\n"
     ]
    }
   ],
   "source": [
    "conditions = list(embeddings.keys())\n",
    "print(conditions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "distances = [get_distance_array(embeddings[condition])\n",
    "                   for condition in conditions]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt3_ada\n",
      "gpt3_babbage\n",
      "gpt3_curie\n",
      "gpt3_davinci\n",
      "bert\n",
      "human_label\n"
     ]
    }
   ],
   "source": [
    "for x in conditions: print(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.        , 0.20037083, 0.20633172, 0.18682465, 0.16081595,\n        0.18469388, 0.19844114, 0.18363315, 0.19313584, 0.1618257 ,\n        0.22849031, 0.15678066, 0.19342615, 0.12127581, 0.18622777,\n        0.21008724, 0.21138558, 0.19625726, 0.18758157, 0.27973558,\n        0.17560411, 0.18342449, 0.19238455, 0.20467588, 0.17342221,\n        0.1989533 , 0.17606686, 0.19327192, 0.18598225, 0.19471532,\n        0.14955998, 0.22636314],\n       [0.20037083, 0.        , 0.21315364, 0.21040712, 0.16839863,\n        0.21641092, 0.17375067, 0.11336646, 0.18720296, 0.16806214,\n        0.22499673, 0.18413632, 0.21270323, 0.19619273, 0.1881653 ,\n        0.26145295, 0.22326662, 0.21376567, 0.21239476, 0.25709376,\n        0.17829902, 0.16688188, 0.2046902 , 0.21178492, 0.17666986,\n        0.20666023, 0.1759264 , 0.21905431, 0.20262967, 0.20864565,\n        0.16586336, 0.24479995],\n       [0.20633172, 0.21315364, 0.        , 0.1517975 , 0.21927399,\n        0.24658722, 0.23193745, 0.1547803 , 0.21705385, 0.23642683,\n        0.24073987, 0.20805015, 0.21700252, 0.19829471, 0.18126254,\n        0.25761129, 0.25823607, 0.20188954, 0.26175012, 0.2222114 ,\n        0.2363428 , 0.23621821, 0.18407238, 0.17255716, 0.18905128,\n        0.16537166, 0.17396533, 0.19758589, 0.21937474, 0.2296287 ,\n        0.18908637, 0.26519498],\n       [0.18682465, 0.21040712, 0.1517975 , 0.        , 0.20059975,\n        0.21609231, 0.22844274, 0.17099215, 0.20747843, 0.20116496,\n        0.13819882, 0.19947451, 0.20716366, 0.19872388, 0.15521641,\n        0.22854283, 0.23057351, 0.21828066, 0.21169877, 0.24064319,\n        0.21030539, 0.22721589, 0.19878959, 0.22000625, 0.17775474,\n        0.16786919, 0.18770759, 0.16922151, 0.21544641, 0.20576035,\n        0.18603492, 0.26875386]])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances[0][0][:4]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.        , 0.30480243, 0.26305467, 0.26494669, 0.21971265,\n        0.22069277, 0.28135243, 0.28088367, 0.28668284, 0.24997453,\n        0.26228406, 0.17791516, 0.21812912, 0.17857343, 0.26509828,\n        0.24238802, 0.24554417, 0.26920688, 0.22887032, 0.34231553,\n        0.22420474, 0.23695224, 0.25661139, 0.26385183, 0.24911234,\n        0.2240702 , 0.2253368 , 0.23998121, 0.23726722, 0.20359104,\n        0.19208624, 0.25073903],\n       [0.30480243, 0.        , 0.29192428, 0.30647428, 0.26313416,\n        0.32293597, 0.26433925, 0.17595521, 0.26279374, 0.2925316 ,\n        0.30394604, 0.28889745, 0.28857144, 0.28151082, 0.27876087,\n        0.33059139, 0.30583188, 0.31404515, 0.30162316, 0.34382712,\n        0.27688871, 0.25395032, 0.30879494, 0.2713653 , 0.24674861,\n        0.27402544, 0.25282302, 0.29466678, 0.27435719, 0.27399647,\n        0.26712398, 0.31663654],\n       [0.26305467, 0.29192428, 0.        , 0.24231024, 0.26701302,\n        0.30014194, 0.2947704 , 0.23011353, 0.28381286, 0.30330448,\n        0.32906419, 0.24779666, 0.24865703, 0.25803834, 0.27818333,\n        0.2907355 , 0.32000937, 0.27052131, 0.32487976, 0.31214364,\n        0.3159602 , 0.27921175, 0.24532728, 0.26074652, 0.25320528,\n        0.23378177, 0.22676819, 0.24313673, 0.26201484, 0.24722265,\n        0.2380264 , 0.28747354],\n       [0.26494669, 0.30647428, 0.24231024, 0.        , 0.27058052,\n        0.29750934, 0.3149631 , 0.28866803, 0.30982244, 0.29346149,\n        0.2298736 , 0.27398094, 0.25926382, 0.28108932, 0.27079746,\n        0.28590944, 0.28467228, 0.29044924, 0.29228015, 0.30833827,\n        0.28931609, 0.28771522, 0.26693992, 0.26215692, 0.25768241,\n        0.26280376, 0.26714045, 0.24473682, 0.29101168, 0.27800039,\n        0.28387407, 0.31342166]])"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances[2][0][:4]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'stand at attention': {'image': {'V', 'CP', 'L', 'B'}, 'group': 1, 'embedding': [4.0, \n",
      "['stand at attention', 'stand out in several sports', 'to stand firm']\n",
      "['image', 'group', 'embedding']\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# To refresh my memory of what is what\n",
    "print(str(schemas)[:87])\n",
    "print(list(schemas.keys())[:3])\n",
    "print(list(schemas['stand at attention'].keys()))\n",
    "print(str(schemas['stand at attention']['group']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('gibbs_cluster', {'stand at attention': 1, 'stand out in several sports': 1, 'to stand firm': 2, \"don't stand for such treatment\": 1, 'to stand the test of time': 1, 'united we stand': 2,\n"
     ]
    }
   ],
   "source": [
    "# dict(dict(list))\n",
    "results = defaultdict(lambda: defaultdict(int))\n",
    "# Load Groups clustered by gibbs 1994\n",
    "results['gibbs_cluster'] = { expression: schemas[expression]['group']\n",
    "                             for expression in texts }\n",
    "print(str(results.items())[:200])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# Load gpt3 text completion calculation\n",
    "\n",
    "n=0\n",
    "def save_response(response):\n",
    "    global n\n",
    "    n=+1\n",
    "\n",
    "    response_text = response.get(\"choices\")[0]['text']\n",
    "    with open(f'data/response_{n}', 'w') as file:\n",
    "        file.write(response_text)\n",
    "\n",
    "    request = { 'params' : params,\n",
    "                'prompt' : prompt,\n",
    "                'response' : response}\n",
    "    with open(f'request_{n}.json', 'w') as json_file:\n",
    "            json.dump(request, json_file, sort_keys=True, indent=4)\n",
    "\n",
    "def generate_response(prompt, params):\n",
    "    response = openai.Completion.create(\n",
    "        engine=params['engine'],\n",
    "        prompt=prompt,\n",
    "        max_tokens=params['max_tokens'],\n",
    "        temperature=params['temperature'],\n",
    "        top_p=params['top_p'],\n",
    "        frequency_penalty=params['frequency_penalty'],\n",
    "        presence_penalty=params['presence_penalty'])\n",
    "    save_response(response)\n",
    "    return response\n",
    "\n",
    "generate = False\n",
    "# generate = True\n",
    "if generate:\n",
    "    with open('data/params.json') as json_file:\n",
    "        params = json.load(json_file)\n",
    "    with open('data/prompt') as file:\n",
    "        prompt = file.read()\n",
    "    response = generate_response(prompt, params)\n",
    "\n",
    "with open('data/stand_request_04.csv') as file:\n",
    "    read_csv = csv.reader(file, delimiter='\\t')\n",
    "    # remove header\n",
    "    header = next(read_csv)\n",
    "    gpt_groups = {expression: int(group) for expression, group in read_csv}\n",
    "\n",
    "results['gpt3_gibbs_completion'] = gpt_groups"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "cluster = AgglomerativeClustering(n_clusters=3,\n",
    "                   affinity='precomputed', linkage='complete')\n",
    "\n",
    "for (distance_array, distance_matrix), condition in zip(distances, conditions):\n",
    "    cluster_prediction = cluster.fit_predict(distance_array)\n",
    "    for i, prediction in enumerate(cluster_prediction):\n",
    "        expression = distance_matrix.columns[i]\n",
    "        results[condition][expression] = prediction\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from itertools import combinations, permutations\n",
    "\n",
    "cluster_permutations = [np.array(x) for x in permutations([1,2,3], 3)]\n",
    "# for x in cluster_permutations: print(x)\n",
    "# [1, 2, 3]\n",
    "# [1, 3, 2]\n",
    "\n",
    "permutation_combinations = [x for x in combinations(cluster_permutations, 2)]\n",
    "# for x in permutation_combinations: print(x)\n",
    "# ([1, 2, 3], [1, 3, 2])\n",
    "# ([1, 2, 3], [2, 1, 3])\n",
    "\n",
    "def replace_values(a, old_values, new_values):\n",
    "    arr = np.empty(a.max()+1, dtype=new_values.dtype)\n",
    "    arr[old_values] = new_values\n",
    "    return arr[a]\n",
    "\n",
    "def clean_values(a):\n",
    "    arr = np.array(a)\n",
    "    value_range = set(a)\n",
    "    if not 0 in value_range:\n",
    "        return arr, [ x for x in value_range ]\n",
    "    old_values = [0, 1, 2]\n",
    "    new_values = [1, 2, 3]\n",
    "    arr = replace_values(arr, np.array(old_values), np.array(new_values))\n",
    "    return arr, list(zip(old_values, new_values))\n",
    "\n",
    "stat_results = list()\n",
    "\n",
    "for a, b in permutations(results.keys(), 2):\n",
    "    tps=list()\n",
    "    group_a = list()\n",
    "    group_b = list()\n",
    "    for text in results[a].keys():\n",
    "        if text in results[b].keys():\n",
    "            group_b.append(results[b][text])\n",
    "            group_a.append(results[a][text])\n",
    "\n",
    "    group_a, value_remap_a = clean_values(group_a)\n",
    "    group_b, value_remap_b = clean_values(group_b)\n",
    "\n",
    "    for old_values, new_values in permutation_combinations:\n",
    "        tps.append([stats.ttest_rel(group_a, group_b),\n",
    "                    value_remap_a,\n",
    "                    zip((value_remap_b, list(old_values))) ])\n",
    "        group_b = replace_values(group_a, old_values, new_values)\n",
    "    tp, value_remap_a, value_remap_b = max(tps, key=lambda x: x[0][0])\n",
    "    stat_results.append([a,b,tp[0],tp[1],value_remap_a,value_remap_b])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "p_df = pd.DataFrame(stat_results,\n",
    "                    columns=['cond1', 'cond2', 't', 'p', 'value_remap_1', 'value_remap_2'])\n",
    "p_matrix = pd.pivot_table(p_df, values='p', index='cond1', columns='cond2')\n",
    "t_matrix = pd.pivot_table(p_df, values='t', index='cond1', columns='cond2')\n",
    "\n",
    "p_df.to_csv('data/results_df.csv')\n",
    "p_matrix.to_csv('data/results_p_matrix.csv')\n",
    "t_matrix.to_csv('data/results_t_matrix.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "cond2                      bert  gibbs_cluster  gpt3_ada  gpt3_babbage  \\\ncond1                                                                    \nbert                        NaN       2.265491  3.303860      2.265491   \ngibbs_cluster          0.891556            NaN  2.440669      0.891556   \ngpt3_ada               0.176866       0.176866       NaN      0.176866   \ngpt3_babbage           5.637802       5.637802  5.637802           NaN   \ngpt3_curie             5.299494       5.299494  5.299494      5.299494   \ngpt3_davinci           1.437591       1.437591  1.437591      1.437591   \ngpt3_gibbs_completion  5.357584       5.357584  6.338366      5.357584   \nhuman_label            2.674667       2.674667  4.051144      2.674667   \n\ncond2                  gpt3_curie  gpt3_davinci  gpt3_gibbs_completion  \\\ncond1                                                                    \nbert                     2.265491      3.644957               2.265491   \ngibbs_cluster            0.891556      2.805615               0.891556   \ngpt3_ada                 0.176866      0.891556               0.176866   \ngpt3_babbage             5.637802      5.637802               5.637802   \ngpt3_curie                    NaN      5.299494               5.299494   \ngpt3_davinci             1.437591           NaN               1.437591   \ngpt3_gibbs_completion    5.357584      6.523138                    NaN   \nhuman_label              2.674667      4.625404               2.674667   \n\ncond2                  human_label  \ncond1                               \nbert                      2.265491  \ngibbs_cluster             0.891556  \ngpt3_ada                  0.176866  \ngpt3_babbage              5.637802  \ngpt3_curie                5.299494  \ngpt3_davinci              1.437591  \ngpt3_gibbs_completion     5.357584  \nhuman_label                    NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>cond2</th>\n      <th>bert</th>\n      <th>gibbs_cluster</th>\n      <th>gpt3_ada</th>\n      <th>gpt3_babbage</th>\n      <th>gpt3_curie</th>\n      <th>gpt3_davinci</th>\n      <th>gpt3_gibbs_completion</th>\n      <th>human_label</th>\n    </tr>\n    <tr>\n      <th>cond1</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>bert</th>\n      <td>NaN</td>\n      <td>2.265491</td>\n      <td>3.303860</td>\n      <td>2.265491</td>\n      <td>2.265491</td>\n      <td>3.644957</td>\n      <td>2.265491</td>\n      <td>2.265491</td>\n    </tr>\n    <tr>\n      <th>gibbs_cluster</th>\n      <td>0.891556</td>\n      <td>NaN</td>\n      <td>2.440669</td>\n      <td>0.891556</td>\n      <td>0.891556</td>\n      <td>2.805615</td>\n      <td>0.891556</td>\n      <td>0.891556</td>\n    </tr>\n    <tr>\n      <th>gpt3_ada</th>\n      <td>0.176866</td>\n      <td>0.176866</td>\n      <td>NaN</td>\n      <td>0.176866</td>\n      <td>0.176866</td>\n      <td>0.891556</td>\n      <td>0.176866</td>\n      <td>0.176866</td>\n    </tr>\n    <tr>\n      <th>gpt3_babbage</th>\n      <td>5.637802</td>\n      <td>5.637802</td>\n      <td>5.637802</td>\n      <td>NaN</td>\n      <td>5.637802</td>\n      <td>5.637802</td>\n      <td>5.637802</td>\n      <td>5.637802</td>\n    </tr>\n    <tr>\n      <th>gpt3_curie</th>\n      <td>5.299494</td>\n      <td>5.299494</td>\n      <td>5.299494</td>\n      <td>5.299494</td>\n      <td>NaN</td>\n      <td>5.299494</td>\n      <td>5.299494</td>\n      <td>5.299494</td>\n    </tr>\n    <tr>\n      <th>gpt3_davinci</th>\n      <td>1.437591</td>\n      <td>1.437591</td>\n      <td>1.437591</td>\n      <td>1.437591</td>\n      <td>1.437591</td>\n      <td>NaN</td>\n      <td>1.437591</td>\n      <td>1.437591</td>\n    </tr>\n    <tr>\n      <th>gpt3_gibbs_completion</th>\n      <td>5.357584</td>\n      <td>5.357584</td>\n      <td>6.338366</td>\n      <td>5.357584</td>\n      <td>5.357584</td>\n      <td>6.523138</td>\n      <td>NaN</td>\n      <td>5.357584</td>\n    </tr>\n    <tr>\n      <th>human_label</th>\n      <td>2.674667</td>\n      <td>2.674667</td>\n      <td>4.051144</td>\n      <td>2.674667</td>\n      <td>2.674667</td>\n      <td>4.625404</td>\n      <td>2.674667</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "cond2                      bert  gibbs_cluster      gpt3_ada  gpt3_babbage  \\\ncond1                                                                        \nbert                        NaN       0.030617  2.412358e-03      0.030617   \ngibbs_cluster          0.379499            NaN  2.057057e-02      0.379499   \ngpt3_ada               0.860764       0.860764           NaN      0.860764   \ngpt3_babbage           0.000003       0.000003  3.450532e-06           NaN   \ngpt3_curie             0.000009       0.000009  9.098660e-06      0.000009   \ngpt3_davinci           0.160569       0.160569  1.605686e-01      0.160569   \ngpt3_gibbs_completion  0.000008       0.000008  4.702546e-07      0.000008   \nhuman_label            0.011834       0.011834  3.168301e-04      0.011834   \n\ncond2                  gpt3_curie  gpt3_davinci  gpt3_gibbs_completion  \\\ncond1                                                                    \nbert                     0.030617  9.692861e-04               0.030617   \ngibbs_cluster            0.379499  8.598400e-03               0.379499   \ngpt3_ada                 0.860764  3.794992e-01               0.860764   \ngpt3_babbage             0.000003  3.450532e-06               0.000003   \ngpt3_curie                    NaN  9.098660e-06               0.000009   \ngpt3_davinci             0.160569           NaN               0.160569   \ngpt3_gibbs_completion    0.000008  2.795196e-07                    NaN   \nhuman_label              0.011834  6.266547e-05               0.011834   \n\ncond2                  human_label  \ncond1                               \nbert                      0.030617  \ngibbs_cluster             0.379499  \ngpt3_ada                  0.860764  \ngpt3_babbage              0.000003  \ngpt3_curie                0.000009  \ngpt3_davinci              0.160569  \ngpt3_gibbs_completion     0.000008  \nhuman_label                    NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>cond2</th>\n      <th>bert</th>\n      <th>gibbs_cluster</th>\n      <th>gpt3_ada</th>\n      <th>gpt3_babbage</th>\n      <th>gpt3_curie</th>\n      <th>gpt3_davinci</th>\n      <th>gpt3_gibbs_completion</th>\n      <th>human_label</th>\n    </tr>\n    <tr>\n      <th>cond1</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>bert</th>\n      <td>NaN</td>\n      <td>0.030617</td>\n      <td>2.412358e-03</td>\n      <td>0.030617</td>\n      <td>0.030617</td>\n      <td>9.692861e-04</td>\n      <td>0.030617</td>\n      <td>0.030617</td>\n    </tr>\n    <tr>\n      <th>gibbs_cluster</th>\n      <td>0.379499</td>\n      <td>NaN</td>\n      <td>2.057057e-02</td>\n      <td>0.379499</td>\n      <td>0.379499</td>\n      <td>8.598400e-03</td>\n      <td>0.379499</td>\n      <td>0.379499</td>\n    </tr>\n    <tr>\n      <th>gpt3_ada</th>\n      <td>0.860764</td>\n      <td>0.860764</td>\n      <td>NaN</td>\n      <td>0.860764</td>\n      <td>0.860764</td>\n      <td>3.794992e-01</td>\n      <td>0.860764</td>\n      <td>0.860764</td>\n    </tr>\n    <tr>\n      <th>gpt3_babbage</th>\n      <td>0.000003</td>\n      <td>0.000003</td>\n      <td>3.450532e-06</td>\n      <td>NaN</td>\n      <td>0.000003</td>\n      <td>3.450532e-06</td>\n      <td>0.000003</td>\n      <td>0.000003</td>\n    </tr>\n    <tr>\n      <th>gpt3_curie</th>\n      <td>0.000009</td>\n      <td>0.000009</td>\n      <td>9.098660e-06</td>\n      <td>0.000009</td>\n      <td>NaN</td>\n      <td>9.098660e-06</td>\n      <td>0.000009</td>\n      <td>0.000009</td>\n    </tr>\n    <tr>\n      <th>gpt3_davinci</th>\n      <td>0.160569</td>\n      <td>0.160569</td>\n      <td>1.605686e-01</td>\n      <td>0.160569</td>\n      <td>0.160569</td>\n      <td>NaN</td>\n      <td>0.160569</td>\n      <td>0.160569</td>\n    </tr>\n    <tr>\n      <th>gpt3_gibbs_completion</th>\n      <td>0.000008</td>\n      <td>0.000008</td>\n      <td>4.702546e-07</td>\n      <td>0.000008</td>\n      <td>0.000008</td>\n      <td>2.795196e-07</td>\n      <td>NaN</td>\n      <td>0.000008</td>\n    </tr>\n    <tr>\n      <th>human_label</th>\n      <td>0.011834</td>\n      <td>0.011834</td>\n      <td>3.168301e-04</td>\n      <td>0.011834</td>\n      <td>0.011834</td>\n      <td>6.266547e-05</td>\n      <td>0.011834</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}